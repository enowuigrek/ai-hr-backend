const express = require('express');
const router = express.Router();
const OpenAI = require('openai');

// Rate limiting middleware
let rateLimitMiddleware;
try { 
  ({ rateLimitMiddleware } = require('../middleware/rateLimit')); 
} catch { 
  rateLimitMiddleware = (req,res,next)=>next(); 
}

// HR service for knowledge base and filtering
const { getSystemPrompt, isHRRelated, getFallbackResponse } = require('../services/hrService');

// Database service for saving conversations
const dbService = require('../services/dbService');

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// POST /api/chat - g≈Ç√≥wny endpoint
router.post('/', rateLimitMiddleware, async (req, res) => {
  const started = Date.now();

  try {
    const { message, sessionId } = req.body || {};
    
    // Walidacja message
    if (!message || typeof message !== 'string') {
      return res.status(400).json({ error: 'Message is required', code: 'INVALID_MESSAGE' });
    }

    // Walidacja sessionId
    if (!sessionId || typeof sessionId !== 'string' || sessionId.length > 100) {
      return res.status(400).json({ error: 'Invalid sessionId', code: 'INVALID_SESSION_ID' });
    }

    // 1) Sprawd≈∫ czy pytanie jest zwiƒÖzane z HR (opcjonalne - mo≈ºna wy≈ÇƒÖczyƒá)
    // if (!isHRRelated(message)) {
    //   const responseTime = Date.now() - started;
    //   return res.json({
    //     success: true,
    //     response: getFallbackResponse(message),
    //     sessionId,
    //     timestamp: new Date().toISOString(),
    //     responseTime,
    //     source: 'hr-filter'
    //   });
    // }

    // 2) Zbuduj system prompt z bazy wiedzy (TEST/PROD)
    const systemPrompt = getSystemPrompt();

    // 3) üöÄ NOWE: Pobierz ostatnie 4 pary konwersacji dla kontekstu
    console.log('üìö Loading recent conversation context for session:', sessionId);
    const recentContext = await dbService.getRecentConversationContext(sessionId, 4); // 4 ostatnie pary pytanie-odpowied≈∫
    console.log('üìö Recent context loaded:', {
      sessionId,
      contextPairs: recentContext.messages.length,
      total: recentContext.total
    });

    // 4) Przygotuj user message (obciƒôcie do 5000 znak√≥w)
    const userMessage = String(message).slice(0, 5000);

    // 5) Z≈Ç√≥≈º wiadomo≈õci dla OpenAI z KONTEKSTEM üéØ
    const messages = [
      {
        role: 'system',
        content: systemPrompt + 
          '\n\nZASADA TWARDA: Odpowiadaj TYLKO na podstawie powy≈ºszego tekstu. ' +
          'Je≈õli w bazie nie ma informacji ‚Äì odpowiedz dok≈Çadnie: "Brak danych w bazie".' +
          '\n\nüî•üî•üî• KRYTYCZNE: OBS≈ÅUGA KONTEKSTU ROZMOWY üî•üî•üî•' +
          '\nCZYTAJ UWA≈ªNIE POPRZEDNIE WIADOMO≈öCI W TEJ ROZMOWIE!' +
          '\n\nüìã ZASADY:' +
          '\n1. Je≈õli wcze≈õniej pyta≈Çe≈õ "Ile lat pracujesz?" a u≈ºytkownik teraz pisze "10 lat" - TO JEST ODPOWIED≈π!' +
          '\n2. Je≈õli pyta≈Çe≈õ "26 dni urlopu?" a u≈ºytkownik pisze "26" - POTWIERDZA 26 dni!' +
          '\n3. Je≈õli pyta≈Çe≈õ o sta≈º i u≈ºytkownik odpowiedzia≈Ç "10 lat", NIE PYTAJ PONOWNIE o sta≈º!' +
          '\n4. WYKORZYSTAJ dane z poprzednich odpowiedzi do oblicze≈Ñ!' +
          '\n\nüí° PRZYK≈ÅAD DOBREJ ROZMOWY:' +
          '\nTy: "Ile lat pracujesz?"' +
          '\nUser: "10 lat"' +
          '\nTy: "Skoro pracujesz 10 lat, przys≈Çuguje Ci 3 miesiƒÖce wypowiedzenia"' +
          '\n\n‚ùå NIE R√ìB TAK:' +
          '\nTy: "Ile lat pracujesz?"' +
          '\nUser: "10 lat"' +
          '\nTy: "Ile lat pracujesz?" ‚Üê B≈ÅƒÑD!' +
          '\n\nüß† PAMIƒòTAJ: Je≈õli widzisz wcze≈õniejsze pytania i odpowiedzi, U≈ªYJ ICH!'
      }
    ];

    // DODAJ KONTEKST OSTATNICH KONWERSACJI
    if (recentContext.messages && recentContext.messages.length > 0) {
      console.log('üîó Adding recent conversation context to OpenAI messages');
      recentContext.messages.forEach(msg => {
        messages.push(
          { role: 'user', content: msg.user_message },
          { role: 'assistant', content: msg.ai_response }
        );
      });
    }

    // DODAJ AKTUALNE PYTANIE na ko≈Ñcu
    messages.push({ 
      role: 'user', 
      content: userMessage 
    });

    // Debug: sprawd≈∫ strukturƒô wiadomo≈õci
    console.log('ü§ñ Sending to OpenAI with context:', {
      sessionId,
      totalMessages: messages.length,
      systemPrompt: 1,
      contextPairs: recentContext.messages.length,
      currentMessage: 1,
      currentMessagePreview: userMessage.substring(0, 50) + '...',
      messagesStructure: messages.map((msg, i) => ({
        index: i,
        role: msg.role,
        contentLength: msg.content.length,
        preview: msg.role === 'system' ? '[SYSTEM PROMPT]' : msg.content.substring(0, 100) + '...'
      }))
    });

    // üö® FORCE DEBUG - poka≈º DOK≈ÅADNIE co wysy≈Çamy do OpenAI
    console.log('üö® FULL MESSAGES ARRAY BEING SENT TO OPENAI:');
    messages.forEach((msg, index) => {
      console.log(`Message ${index} (${msg.role}):`, 
        msg.role === 'system' ? '[SYSTEM PROMPT - HIDDEN]' : `"${msg.content}"`
      );
    });

    // 6) Wywo≈Çanie OpenAI z lepszymi parametrami dla kontekstu
    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages,
      temperature: 0.2, // Niska temperatura dla konsystentnych odpowiedzi
      max_tokens: 600,
      presence_penalty: 0.1, // Lekko karze powtarzanie
      frequency_penalty: 0.1 // Lekko zachƒôca do r√≥≈ºnorodno≈õci
    });

    const aiText = completion?.choices?.[0]?.message?.content?.trim() || 'Brak danych w bazie';
    
    // 7) Oblicz czas odpowiedzi
    const responseTime = Date.now() - started;

    // 8) Zapisz rozmowƒô w bazie danych
    try {
      console.log('üîÑ Attempting to save to DB:', {
        sessionId,
        userMessageLength: userMessage.length,
        aiResponseLength: aiText.length,
        responseTime
      });
      await dbService.saveConversation(sessionId, userMessage, aiText, responseTime);
      console.log('‚úÖ DB save successful');
    } catch (e) {
      console.error('‚ùå DB save failed:', e?.message || e);
      // Nie blokuj odpowiedzi je≈õli zapis siƒô nie uda
    }

    // 9) Zwr√≥ƒá odpowied≈∫ z dodatkowymi info
    return res.json({
      success: true,
      response: aiText,
      sessionId,
      timestamp: new Date().toISOString(),
      responseTime,
      source: 'openai-gpt-4o-mini',
      // Debug info (mo≈ºesz usunƒÖƒá w produkcji)
      context: {
        contextPairsUsed: recentContext.messages.length,
        totalMessagesInPrompt: messages.length - 1, // -1 bo system prompt
        hasHistory: recentContext.messages.length > 0
      }
    });

  } catch (error) {
    console.error('‚ùå Chat error:', error);
    const responseTime = Date.now() - started;
    
    // Je≈õli b≈ÇƒÖd OpenAI - spr√≥buj fallback
    if (error.code === 'insufficient_quota' || error.code === 'invalid_api_key') {
      console.log('üîÑ OpenAI error - using fallback response');
      try {
        const fallbackResponse = getFallbackResponse(req.body.message || 'Pytanie o HR');
        return res.json({
          success: true,
          response: fallbackResponse,
          sessionId: req.body.sessionId,
          timestamp: new Date().toISOString(),
          responseTime,
          source: 'fallback-due-to-openai-error'
        });
      } catch (fallbackError) {
        console.error('‚ùå Fallback also failed:', fallbackError);
      }
    }
    
    return res.status(500).json({
      error: 'Chat processing failed',
      code: 'CHAT_ERROR',
      responseTime,
      details: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

module.exports = router;